// src/ai/flows/interpret-musical-intent.ts
'use server';

/**
 * @fileOverview This file defines a Genkit flow to interpret user musical intent.
 * It now synthesizes free-text mood, Mood Composer selections, and advanced filters
 * into a rich search query for Spotify.
 *
 * @exported
 * - `InterpretMusicalIntentInput`: The input type for the interpretMusicalIntent function.
 * - `InterpretMusicalIntentOutput`: The return type for the interpretMusicalIntent function.
 * - `interpretMusicalIntent`: The function that handles the musical intent interpretation process.
 */

import {ai} from '@/ai/genkit';
import {z}from 'genkit';
import { 
  searchSpotifyTrackService 
} from '@/services/spotify-service';

// +---------------------+
// |   INPUT SCHEMA      |
// +---------------------+
const MoodComposerSelectionsSchema = z.object({
  selectedMoodDisplayName: z.string().optional().describe("The user-friendly display name of the selected mood profile from MoodComposer."),
  energy: z.number().min(0).max(1).optional().describe("Energy level (0.0-1.0) from MoodComposer slider."),
  valence: z.number().min(0).max(1).optional().describe("Valence/positiveness level (0.0-1.0) from MoodComposer slider."),
  tempo: z.number().min(40).max(240).optional().describe("Target tempo in BPM from MoodComposer input."),
  languages: z.array(z.string()).optional().describe("Selected languages from MoodComposer (e.g., ['Japanese', 'Spanish'])."),
  associatedKeywords: z.array(z.string()).optional().describe("Search keywords associated with the selectedMoodDisplayName from moods.json.")
}).optional();

const InterpretMusicalIntentInputSchema = z.object({
  moodDescription: z.string().optional().describe('User-provided free-text description of the mood or vibe.'),
  songName: z.string().optional().describe('An optional specific song name to influence the search query.'),
  instrumentTags: z.string().optional().describe('Optional comma-separated list of key instruments (e.g., guitar, piano).'),
  moodComposerSelections: MoodComposerSelectionsSchema.describe("Structured selections from the MoodComposer UI."),
});
export type InterpretMusicalIntentInput = z.infer<typeof InterpretMusicalIntentInputSchema>;

// +---------------------+
// |   OUTPUT SCHEMA     |
// +---------------------+
const InterpretMusicalIntentOutputSchema = z.object({
  fallbackSearchQuery: z.string().describe("A rich and descriptive search query string for Spotify. Example: 'upbeat electronic music with piano like the song Levitating for a summer road trip'")
}).describe("A search query for Spotify, generated by translating the user's vibe and selections.");
export type InterpretMusicalIntentOutput = z.infer<typeof InterpretMusicalIntentOutputSchema>;


// +---------------------+
// |   GENKIT TOOLS      |
// +---------------------+
const getSpotifyTrackInfoTool = ai.defineTool(
  {
    name: 'getSpotifyTrackInfoTool',
    description: 'Searches Spotify for a track by name and returns its name and primary artist if found. Useful for creating "music like [song by artist]" queries.',
    inputSchema: z.object({ 
      trackName: z.string().describe("The name of the track to search for."),
    }),
    outputSchema: z.object({
        foundTrackName: z.string().nullable().describe("The Spotify track name, or null if not found."),
        foundArtistName: z.string().nullable().describe("The primary artist of the track, or null if not found."),
    }).nullable().describe("An object containing the track name and artist name, or null if track not found."),
  },
  async ({ trackName }) => {
    try {
      const tracks = await searchSpotifyTrackService(trackName, undefined, 1);
      if (tracks[0]) {
        return {
          foundTrackName: tracks[0].name,
          foundArtistName: tracks[0].artists[0]?.name || null,
        };
      }
      return null;
    } catch (error) {
      console.error("Error in getSpotifyTrackInfoTool:", error);
      return null;
    }
  }
);


// +---------------------+
// |   MAIN PROMPT       |
// +---------------------+
const interpretMusicalIntentPrompt = ai.definePrompt({
  name: 'interpretMusicalIntentPrompt',
  input: {schema: InterpretMusicalIntentInputSchema},
  output: {schema: InterpretMusicalIntentOutputSchema},
  tools: [getSpotifyTrackInfoTool],
  prompt: `You are an expert music curator. Your primary task is to synthesize all available user inputs into a single, rich, and descriptive search query for Spotify. This query should capture the *essence* and *musical characteristics* of the desired vibe.

User Inputs:
1.  **Free-Text Vibe Description (moodDescription)**: "{{{moodDescription}}}"
    *   This is a key expression of the user's desired feel. If specific (e.g., "Ballet music", "Jazz for a rainy day"), your query MUST reflect that.

2.  **Mood Composer Selections (moodComposerSelections)** (if provided):
    *   Selected Mood Profile: "{{moodComposerSelections.selectedMoodDisplayName}}"
    *   Associated Keywords for this profile: {{#if moodComposerSelections.associatedKeywords}} "{{#each moodComposerSelections.associatedKeywords}}{{{this}}}{{#unless @last}}, {{/unless}}{{/each}}" {{else}}None{{/if}}
    *   Energy level: {{#if moodComposerSelections.energy}}{{moodComposerSelections.energy}} (0-1 scale){{else}}Not specified{{/if}}
    *   Valence (positiveness): {{#if moodComposerSelections.valence}}{{moodComposerSelections.valence}} (0-1 scale){{else}}Not specified{{/if}}
    *   Target Tempo: {{#if moodComposerSelections.tempo}}{{moodComposerSelections.tempo}} BPM{{else}}Not specified{{/if}}
    *   Preferred Languages: {{#if moodComposerSelections.languages}} "{{#each moodComposerSelections.languages}}{{{this}}}{{#unless @last}}, {{/unless}}{{/each}}" {{else}}Not specified{{/if}}
    *   Use these structured inputs as strong thematic starting points and to infer musical qualities.

3.  **Optional Song/Instrument Filters**:
    *   Specific Song Name (songName): "{{{songName}}}"
    *   Key Instruments (instrumentTags): "{{{instrumentTags}}}"

You have access to the following tool:
- \`getSpotifyTrackInfoTool({ trackName: string })\`: Searches for a track by its name. If found, it returns the track's name and primary artist's name.

Construct the \`fallbackSearchQuery\` based on ALL information:
1.  **Synthesize Inputs**: Combine insights from \`moodDescription\`, \`moodComposerSelections\`, \`songName\`, and \`instrumentTags\`.
    *   If \`moodDescription\` is specific (e.g., "Ballet", "Jazz for a rainy day"), it should heavily influence the query.
    *   Use \`moodComposerSelections.selectedMoodDisplayName\` and \`moodComposerSelections.associatedKeywords\` as thematic guides.
    *   Translate \`moodComposerSelections.energy\` and \`moodComposerSelections.valence\` into descriptive terms (e.g., high energy, calm, joyful, melancholic).
    *   If \`moodComposerSelections.tempo\` is specified, incorporate terms like "fast tempo", "slow tempo".
    *   **Language Integration (CRITICAL)**: If \`moodComposerSelections.languages\` are provided (e.g., ["Tamil", "Japanese"]), the search query MUST strongly reflect these. Add terms like "Tamil music", "songs in Japanese", "featuring Tamil vocals", or "Japanese pop influences". For example, if mood is "chill" and language is "Tamil", the query could be "chill Tamil music" or "relaxing songs in Tamil". This is a high-priority instruction.
2.  **Song Name Integration**: If \`songName\` is provided, use \`getSpotifyTrackInfoTool\`. If found, incorporate it like: "music with a vibe like '{{foundTrackName}}' by '{{foundArtistName}}'".
3.  **Instrument Integration**: Weave \`instrumentTags\` naturally (e.g., "featuring {{instrumentTags}}", "songs with prominent piano").
4.  **Query Crafting**:
    *   Create a single, natural language phrase.
    *   Aim for 3-7 significant terms.
    *   Example for \`moodDescription\`="Ballet", \`moodComposerSelections.selectedMoodDisplayName\`="Focused Study", \`instrumentTags\`="piano": "classical ballet piano music for focus".
    *   Example for \`moodDescription\`="late night drive", \`songName\`="Strobe", \`moodComposerSelections.energy\`=0.4: "atmospheric electronic music for a late night drive, with a vibe like 'Strobe' by deadmau5, moderately calm energy".
5.  **Fallback**: If inputs are extremely vague, generate a query like "popular upbeat electronic music" or "trending indie folk songs". Avoid overly generic "popular music" if a slightly more descriptive query is possible.

The output MUST be a JSON object with only the \`fallbackSearchQuery\` field.
Example Output:
{
  "fallbackSearchQuery": "upbeat 80s synthwave with prominent synthesizers for a summer road trip"
}
Ensure the output is valid JSON matching the schema.
`,
});

// +---------------------+
// |   FLOW DEFINITION   |
// +---------------------+
const interpretMusicalIntentFlow = ai.defineFlow(
  {
    name: 'interpretMusicalIntentFlow',
    inputSchema: InterpretMusicalIntentInputSchema,
    outputSchema: InterpretMusicalIntentOutputSchema,
  },
  async (input) => {
    console.log("interpretMusicalIntentFlow input:", JSON.stringify(input, null, 2));
    const {output} = await interpretMusicalIntentPrompt(input);

    if (!output || !output.fallbackSearchQuery || output.fallbackSearchQuery.trim() === "") {
        console.warn("AI prompt 'interpretMusicalIntentPrompt' did not return a valid fallbackSearchQuery for input:", input, "Generated output:", JSON.stringify(output));
        
        let fallback = "";
        if (input.moodDescription && input.moodDescription.trim() !== "") {
            const lcMood = input.moodDescription.toLowerCase();
            if (lcMood.includes("ballet") || lcMood.includes("jazz") || lcMood.includes("classical") || lcMood.includes("workout") || lcMood.includes("study")) {
                fallback = `${input.moodDescription} music`;
            } else {
                fallback = `music for ${input.moodDescription}`;
            }
        } else if (input.moodComposerSelections?.selectedMoodDisplayName) {
            fallback = `music for ${input.moodComposerSelections.selectedMoodDisplayName}`;
            if (input.moodComposerSelections.associatedKeywords && input.moodComposerSelections.associatedKeywords.length > 0) {
                fallback += ` ${input.moodComposerSelections.associatedKeywords.join(' ')}`;
            }
        } else {
            fallback = "popular music";
        }
        
        if (input.instrumentTags && input.instrumentTags.trim() !== '') {
            if (!fallback.toLowerCase().includes(input.instrumentTags.toLowerCase())) {
                 fallback += ` with ${input.instrumentTags}`;
            }
        }
        if (input.songName && input.songName.trim() !== '') {
            if (!fallback.toLowerCase().includes(input.songName.toLowerCase())) {
                 fallback += ` like ${input.songName}`;
            }
        }
        
        // Explicitly add language to fallback if not already present
        if (input.moodComposerSelections?.languages && input.moodComposerSelections.languages.length > 0) {
            for (const lang of input.moodComposerSelections.languages) {
                const langQueryPart = `${lang} music`; // e.g., "Tamil music"
                if (!fallback.toLowerCase().includes(lang.toLowerCase())) { // Check if lang itself or "lang music" is present
                    fallback += ` ${langQueryPart}`;
                }
            }
        }

        console.log("interpretMusicalIntentFlow: Using constructed fallback query:", fallback.trim());
        return { fallbackSearchQuery: fallback.trim() };
    }
    
    console.log("interpretMusicalIntentFlow output:", JSON.stringify(output));
    return output;
  }
);

// +---------------------+
// | EXPORTED FUNCTION   |
// +---------------------+
export async function interpretMusicalIntent(input: InterpretMusicalIntentInput): Promise<InterpretMusicalIntentOutput> {
  return interpretMusicalIntentFlow(input);
}
